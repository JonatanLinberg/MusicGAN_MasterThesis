{"cells":[{"cell_type":"markdown","metadata":{"id":"ih7AKcfR3eo8"},"source":["## Importing and Defining Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38219,"status":"ok","timestamp":1677784675005,"user":{"displayName":"Jonatan Linberg","userId":"01128255743223518754"},"user_tz":-60},"id":"7xo-JQ-NADhs","outputId":"d3ab6c5f-633e-41d2-acb8-c187b82b323c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["try:\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=True)\n","  path_top = '/content/drive/MyDrive/Master Thesis/'\n","except Exception as e:\n","  print(e)\n","  path_top = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15105,"status":"ok","timestamp":1677784690102,"user":{"displayName":"Jonatan Linberg","userId":"01128255743223518754"},"user_tz":-60},"id":"a_aOFzkQ3eo9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a208a81d-bb6b-4c08-e60b-04907c55b9c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qqq tensorflow_addons\n","!pip install -qqq tensorflow-io\n","!cp /content/drive/MyDrive/Master\\ Thesis/repo/code/params.py .\n","!cp /content/drive/MyDrive/Master\\ Thesis/repo/code/melspec.py ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QH7S6-1Z3eo-"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_io as tfio\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow_addons import layers as addon_layers\n","import params\n","from melspec import MelSpec\n","\n","# Setting logger level to avoid input shape warnings\n","tf.get_logger().setLevel(\"ERROR\")\n","\n","# Defining hyperparameters\n","\n","DESIRED_SAMPLES = 1982464  # almost 45 seconds\n","LEARNING_RATE_GEN = 1e-5\n","LEARNING_RATE_DISC = 1e-6\n","BATCH_SIZE = 16\n","\n","INPUT_SHAPE = (None, 22050, 1) # 0.5 sec at 44.1hz, mono\n","VAL_SPLIT = 0.2\n","audio_path  = path_top + 'notebooks/dataset/audio'\n","\n","\n","mse = keras.losses.MeanSquaredError()\n","mae = keras.losses.MeanAbsoluteError()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mApGBFxVCfx5"},"outputs":[],"source":["#from importlib import reload\n","#params = reload(params)"]},{"cell_type":"markdown","metadata":{"id":"nVBoAAGaC02w"},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUZSl-R8DBDk"},"outputs":[],"source":["def load_audio_data():\n","    ds_audio_train = tf.keras.utils.audio_dataset_from_directory(\n","        audio_path,\n","        labels=None,\n","        batch_size=None,\n","        shuffle=False,\n","        seed=None,\n","        validation_split=VAL_SPLIT,\n","        subset='training',\n","        output_sequence_length=(45 * params.SAMPLE_RATE), # 45 seconds\n","        follow_links=True\n","    )\n","\n","    ds_audio_val = tf.keras.utils.audio_dataset_from_directory(\n","        audio_path,\n","        labels=None,\n","        batch_size=None,\n","        shuffle=False,\n","        seed=None,\n","        validation_split=VAL_SPLIT,\n","        subset='validation',\n","        output_sequence_length=(45 * params.SAMPLE_RATE), # 45 seconds\n","        follow_links=True\n","    )\n","    return ds_audio_train, ds_audio_val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1075,"status":"ok","timestamp":1677784886810,"user":{"displayName":"Jonatan Linberg","userId":"01128255743223518754"},"user_tz":-60},"id":"iW9xKUG_Fg8K","outputId":"6d64c6f5-1840-4199-917d-e224921ee578"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1802 files belonging to 1 classes.\n","Using 1442 files for training.\n","Found 1802 files belonging to 1 classes.\n","Using 360 files for validation.\n"]}],"source":["def batch_data(data):\n","    if (len(data) == 0):\n","        return data\n","    data = data[:DESIRED_SAMPLES, 0]\n","    return tf.reshape(data, (32, DESIRED_SAMPLES//32, 1))\n","\n","def prepare_data(data):\n","    return data, data\n","\n","training_data, _ = load_audio_data()\n","training_data = training_data.map(batch_data)\n","training_data = training_data.unbatch()\n","training_data = training_data.map(prepare_data)"]},{"cell_type":"markdown","metadata":{"id":"94EXY9arC1kk"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRaRi69Z3epE"},"outputs":[],"source":["# Creating the residual stack block\n","\n","\n","def residual_stack(input, filters):\n","    \"\"\"Convolutional residual stack with weight normalization.\n","\n","    Args:\n","        filter: int, determines filter size for the residual stack.\n","\n","    Returns:\n","        Residual stack output.\n","    \"\"\"\n","    c1 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n","    )(input)\n","    lrelu1 = layers.LeakyReLU()(c1)\n","    c2 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n","    )(lrelu1)\n","    add1 = layers.Add()([c2, input])\n","\n","    lrelu2 = layers.LeakyReLU()(add1)\n","    c3 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=3, padding=\"same\"), data_init=False\n","    )(lrelu2)\n","    lrelu3 = layers.LeakyReLU()(c3)\n","    c4 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n","    )(lrelu3)\n","    add2 = layers.Add()([add1, c4])\n","\n","    lrelu4 = layers.LeakyReLU()(add2)\n","    c5 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=9, padding=\"same\"), data_init=False\n","    )(lrelu4)\n","    lrelu5 = layers.LeakyReLU()(c5)\n","    c6 = addon_layers.WeightNormalization(\n","        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n","    )(lrelu5)\n","    add3 = layers.Add()([c6, add2])\n","\n","    return add3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOmHa_cd3epF"},"outputs":[],"source":["# Dilated convolutional block consisting of the Residual stack\n","\n","\n","def conv_block(input, conv_dim, upsampling_factor):\n","    \"\"\"Dilated Convolutional Block with weight normalization.\n","\n","    Args:\n","        conv_dim: int, determines filter size for the block.\n","        upsampling_factor: int, scale for upsampling.\n","\n","    Returns:\n","        Dilated convolution block.\n","    \"\"\"\n","    conv_t = addon_layers.WeightNormalization(\n","        layers.Conv1DTranspose(conv_dim, 16, upsampling_factor, padding=\"same\"),\n","        data_init=False,\n","    )(input)\n","    lrelu1 = layers.LeakyReLU()(conv_t)\n","    res_stack = residual_stack(lrelu1, conv_dim)\n","    lrelu2 = layers.LeakyReLU()(res_stack)\n","    return lrelu2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoawKFxj3epH"},"outputs":[],"source":["\n","def discriminator_block(input):\n","    conv1 = addon_layers.WeightNormalization(\n","        layers.Conv1D(16, 15, 1, \"same\"), data_init=False\n","    )(input)\n","    lrelu1 = layers.LeakyReLU()(conv1)\n","    conv2 = addon_layers.WeightNormalization(\n","        layers.Conv1D(64, 41, 4, \"same\", groups=4), data_init=False\n","    )(lrelu1)\n","    lrelu2 = layers.LeakyReLU()(conv2)\n","    conv3 = addon_layers.WeightNormalization(\n","        layers.Conv1D(256, 41, 4, \"same\", groups=16), data_init=False\n","    )(lrelu2)\n","    lrelu3 = layers.LeakyReLU()(conv3)\n","    conv4 = addon_layers.WeightNormalization(\n","        layers.Conv1D(1024, 41, 4, \"same\", groups=64), data_init=False\n","    )(lrelu3)\n","    lrelu4 = layers.LeakyReLU()(conv4)\n","    conv5 = addon_layers.WeightNormalization(\n","        layers.Conv1D(1024, 41, 4, \"same\", groups=256), data_init=False\n","    )(lrelu4)\n","    lrelu5 = layers.LeakyReLU()(conv5)\n","    conv6 = addon_layers.WeightNormalization(\n","        layers.Conv1D(1024, 5, 1, \"same\"), data_init=False\n","    )(lrelu5)\n","    lrelu6 = layers.LeakyReLU()(conv6)\n","    conv7 = addon_layers.WeightNormalization(\n","        layers.Conv1D(1, 3, 1, \"same\"), data_init=False\n","    )(lrelu6)\n","    return [lrelu1, lrelu2, lrelu3, lrelu4, lrelu5, lrelu6, conv7]\n"]},{"cell_type":"markdown","metadata":{"id":"JoKPvy7v3epH"},"source":["### Create the generator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4003,"status":"ok","timestamp":1677784892658,"user":{"displayName":"Jonatan Linberg","userId":"01128255743223518754"},"user_tz":-60},"id":"8PtlnvgJ3epI","outputId":"8a0abf2a-1b74-4508-d988-ca82fae4ab13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_9 (InputLayer)           [(None, None, 1)]    0           []                               \n","                                                                                                  \n"," mel_spec_4 (MelSpec)           (None, None, 256)    0           ['input_9[0][0]']                \n","                                                                                                  \n"," conv1d_188 (Conv1D)            (None, None, 512)    918016      ['mel_spec_4[0][0]']             \n","                                                                                                  \n"," leaky_re_lu_188 (LeakyReLU)    (None, None, 512)    0           ['conv1d_188[0][0]']             \n","                                                                                                  \n"," weight_normalization_200 (Weig  (None, None, 256)   2097921     ['leaky_re_lu_188[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_189 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_200[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_201 (Weig  (None, None, 256)   197121      ['leaky_re_lu_189[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_190 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_201[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_202 (Weig  (None, None, 256)   197121      ['leaky_re_lu_190[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_48 (Add)                   (None, None, 256)    0           ['weight_normalization_202[0][0]'\n","                                                                 , 'leaky_re_lu_189[0][0]']       \n","                                                                                                  \n"," leaky_re_lu_191 (LeakyReLU)    (None, None, 256)    0           ['add_48[0][0]']                 \n","                                                                                                  \n"," weight_normalization_203 (Weig  (None, None, 256)   197121      ['leaky_re_lu_191[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_192 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_203[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_204 (Weig  (None, None, 256)   197121      ['leaky_re_lu_192[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_49 (Add)                   (None, None, 256)    0           ['add_48[0][0]',                 \n","                                                                  'weight_normalization_204[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_193 (LeakyReLU)    (None, None, 256)    0           ['add_49[0][0]']                 \n","                                                                                                  \n"," weight_normalization_205 (Weig  (None, None, 256)   197121      ['leaky_re_lu_193[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_194 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_205[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_206 (Weig  (None, None, 256)   197121      ['leaky_re_lu_194[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_50 (Add)                   (None, None, 256)    0           ['weight_normalization_206[0][0]'\n","                                                                 , 'add_49[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_195 (LeakyReLU)    (None, None, 256)    0           ['add_50[0][0]']                 \n","                                                                                                  \n"," weight_normalization_207 (Weig  (None, None, 128)   524673      ['leaky_re_lu_195[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_196 (LeakyReLU)    (None, None, 128)    0           ['weight_normalization_207[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_208 (Weig  (None, None, 128)   49409       ['leaky_re_lu_196[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_197 (LeakyReLU)    (None, None, 128)    0           ['weight_normalization_208[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_209 (Weig  (None, None, 128)   49409       ['leaky_re_lu_197[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_51 (Add)                   (None, None, 128)    0           ['weight_normalization_209[0][0]'\n","                                                                 , 'leaky_re_lu_196[0][0]']       \n","                                                                                                  \n"," leaky_re_lu_198 (LeakyReLU)    (None, None, 128)    0           ['add_51[0][0]']                 \n","                                                                                                  \n"," weight_normalization_210 (Weig  (None, None, 128)   49409       ['leaky_re_lu_198[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_199 (LeakyReLU)    (None, None, 128)    0           ['weight_normalization_210[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_211 (Weig  (None, None, 128)   49409       ['leaky_re_lu_199[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_52 (Add)                   (None, None, 128)    0           ['add_51[0][0]',                 \n","                                                                  'weight_normalization_211[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_200 (LeakyReLU)    (None, None, 128)    0           ['add_52[0][0]']                 \n","                                                                                                  \n"," weight_normalization_212 (Weig  (None, None, 128)   49409       ['leaky_re_lu_200[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_201 (LeakyReLU)    (None, None, 128)    0           ['weight_normalization_212[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_213 (Weig  (None, None, 128)   49409       ['leaky_re_lu_201[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_53 (Add)                   (None, None, 128)    0           ['weight_normalization_213[0][0]'\n","                                                                 , 'add_52[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_202 (LeakyReLU)    (None, None, 128)    0           ['add_53[0][0]']                 \n","                                                                                                  \n"," weight_normalization_214 (Weig  (None, None, 64)    131265      ['leaky_re_lu_202[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_203 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_214[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_215 (Weig  (None, None, 64)    12417       ['leaky_re_lu_203[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_204 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_215[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_216 (Weig  (None, None, 64)    12417       ['leaky_re_lu_204[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_54 (Add)                   (None, None, 64)     0           ['weight_normalization_216[0][0]'\n","                                                                 , 'leaky_re_lu_203[0][0]']       \n","                                                                                                  \n"," leaky_re_lu_205 (LeakyReLU)    (None, None, 64)     0           ['add_54[0][0]']                 \n","                                                                                                  \n"," weight_normalization_217 (Weig  (None, None, 64)    12417       ['leaky_re_lu_205[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_206 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_217[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_218 (Weig  (None, None, 64)    12417       ['leaky_re_lu_206[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_55 (Add)                   (None, None, 64)     0           ['add_54[0][0]',                 \n","                                                                  'weight_normalization_218[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_207 (LeakyReLU)    (None, None, 64)     0           ['add_55[0][0]']                 \n","                                                                                                  \n"," weight_normalization_219 (Weig  (None, None, 64)    12417       ['leaky_re_lu_207[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_208 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_219[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_220 (Weig  (None, None, 64)    12417       ['leaky_re_lu_208[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_56 (Add)                   (None, None, 64)     0           ['weight_normalization_220[0][0]'\n","                                                                 , 'add_55[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_209 (LeakyReLU)    (None, None, 64)     0           ['add_56[0][0]']                 \n","                                                                                                  \n"," weight_normalization_221 (Weig  (None, None, 32)    32865       ['leaky_re_lu_209[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_210 (LeakyReLU)    (None, None, 32)     0           ['weight_normalization_221[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_222 (Weig  (None, None, 32)    3137        ['leaky_re_lu_210[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_211 (LeakyReLU)    (None, None, 32)     0           ['weight_normalization_222[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_223 (Weig  (None, None, 32)    3137        ['leaky_re_lu_211[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_57 (Add)                   (None, None, 32)     0           ['weight_normalization_223[0][0]'\n","                                                                 , 'leaky_re_lu_210[0][0]']       \n","                                                                                                  \n"," leaky_re_lu_212 (LeakyReLU)    (None, None, 32)     0           ['add_57[0][0]']                 \n","                                                                                                  \n"," weight_normalization_224 (Weig  (None, None, 32)    3137        ['leaky_re_lu_212[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_213 (LeakyReLU)    (None, None, 32)     0           ['weight_normalization_224[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_225 (Weig  (None, None, 32)    3137        ['leaky_re_lu_213[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_58 (Add)                   (None, None, 32)     0           ['add_57[0][0]',                 \n","                                                                  'weight_normalization_225[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_214 (LeakyReLU)    (None, None, 32)     0           ['add_58[0][0]']                 \n","                                                                                                  \n"," weight_normalization_226 (Weig  (None, None, 32)    3137        ['leaky_re_lu_214[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_215 (LeakyReLU)    (None, None, 32)     0           ['weight_normalization_226[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_227 (Weig  (None, None, 32)    3137        ['leaky_re_lu_215[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," add_59 (Add)                   (None, None, 32)     0           ['weight_normalization_227[0][0]'\n","                                                                 , 'add_58[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_216 (LeakyReLU)    (None, None, 32)     0           ['add_59[0][0]']                 \n","                                                                                                  \n"," weight_normalization_228 (Weig  (None, None, 1)     452         ['leaky_re_lu_216[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,277,696\n","Trainable params: 5,277,442\n","Non-trainable params: 254\n","__________________________________________________________________________________________________\n"]}],"source":["\n","def create_generator(input_shape):\n","    inp = keras.Input(input_shape)\n","    x = MelSpec()(inp)\n","    x = layers.Conv1D(512, 7, padding=\"same\")(x)\n","    x = layers.LeakyReLU()(x)\n","    x = conv_block(x, 256, 8)\n","    x = conv_block(x, 128, 8)\n","    x = conv_block(x, 64, 2)\n","    x = conv_block(x, 32, 2)\n","    x = addon_layers.WeightNormalization(\n","        layers.Conv1D(1, 7, padding=\"same\", activation=\"tanh\")\n","    )(x)\n","    return keras.Model(inp, x)\n","\n","\n","# We use a dynamic input shape for the generator since the model is fully convolutional\n","generator = create_generator((None, 1))\n","generator.summary()"]},{"cell_type":"markdown","metadata":{"id":"mNtXxSRi3epI"},"source":["### Create the discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1547,"status":"ok","timestamp":1677784894201,"user":{"displayName":"Jonatan Linberg","userId":"01128255743223518754"},"user_tz":-60},"id":"0YnXrTvt3epJ","outputId":"b07c99d9-011e-48b7-a1f1-5151109f18f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_9\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_10 (InputLayer)          [(None, None, 1)]    0           []                               \n","                                                                                                  \n"," average_pooling1d_8 (AveragePo  (None, None, 1)     0           ['input_10[0][0]']               \n"," oling1D)                                                                                         \n","                                                                                                  \n"," average_pooling1d_9 (AveragePo  (None, None, 1)     0           ['average_pooling1d_8[0][0]']    \n"," oling1D)                                                                                         \n","                                                                                                  \n"," weight_normalization_229 (Weig  (None, None, 16)    273         ['input_10[0][0]']               \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_236 (Weig  (None, None, 16)    273         ['average_pooling1d_8[0][0]']    \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_243 (Weig  (None, None, 16)    273         ['average_pooling1d_9[0][0]']    \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_217 (LeakyReLU)    (None, None, 16)     0           ['weight_normalization_229[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_223 (LeakyReLU)    (None, None, 16)     0           ['weight_normalization_236[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_229 (LeakyReLU)    (None, None, 16)     0           ['weight_normalization_243[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_230 (Weig  (None, None, 64)    10625       ['leaky_re_lu_217[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_237 (Weig  (None, None, 64)    10625       ['leaky_re_lu_223[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_244 (Weig  (None, None, 64)    10625       ['leaky_re_lu_229[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_218 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_230[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_224 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_237[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_230 (LeakyReLU)    (None, None, 64)     0           ['weight_normalization_244[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_231 (Weig  (None, None, 256)   42497       ['leaky_re_lu_218[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_238 (Weig  (None, None, 256)   42497       ['leaky_re_lu_224[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_245 (Weig  (None, None, 256)   42497       ['leaky_re_lu_230[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_219 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_231[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_225 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_238[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_231 (LeakyReLU)    (None, None, 256)    0           ['weight_normalization_245[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_232 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_219[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_239 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_225[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_246 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_231[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_220 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_232[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_226 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_239[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_232 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_246[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_233 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_220[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_240 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_226[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_247 (Weig  (None, None, 1024)  169985      ['leaky_re_lu_232[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_221 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_233[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_227 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_240[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_233 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_247[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_234 (Weig  (None, None, 1024)  5244929     ['leaky_re_lu_221[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_241 (Weig  (None, None, 1024)  5244929     ['leaky_re_lu_227[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_248 (Weig  (None, None, 1024)  5244929     ['leaky_re_lu_233[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_222 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_234[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_228 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_241[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," leaky_re_lu_234 (LeakyReLU)    (None, None, 1024)   0           ['weight_normalization_248[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," weight_normalization_235 (Weig  (None, None, 1)     3075        ['leaky_re_lu_222[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_242 (Weig  (None, None, 1)     3075        ['leaky_re_lu_228[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n"," weight_normalization_249 (Weig  (None, None, 1)     3075        ['leaky_re_lu_234[0][0]']        \n"," htNormalization)                                                                                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 16,924,107\n","Trainable params: 16,924,086\n","Non-trainable params: 21\n","__________________________________________________________________________________________________\n"]}],"source":["\n","def create_discriminator(input_shape):\n","    inp = keras.Input(input_shape)\n","    out_map1 = discriminator_block(inp)\n","    pool1 = layers.AveragePooling1D()(inp)\n","    out_map2 = discriminator_block(pool1)\n","    pool2 = layers.AveragePooling1D()(pool1)\n","    out_map3 = discriminator_block(pool2)\n","    return keras.Model(inp, [out_map1, out_map2, out_map3])\n","\n","\n","# We use a dynamic input shape for the discriminator\n","# This is done because the input shape for the generator is unknown\n","discriminator = create_discriminator((None, 1))\n","\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"4tsAxekL3epJ"},"source":["## Defining the loss functions"]},{"cell_type":"markdown","metadata":{"id":"Npj-f27S3uXw"},"source":["**Generator Loss**\n","\n","The generator architecture uses a combination of two losses\n","\n","1. Mean Squared Error:\n","\n","This is the standard MSE generator loss calculated between ones and the outputs from the\n","discriminator with _N_ layers.\n","\n","<p align=\"center\">\n","<img src=\"https://i.imgur.com/dz4JS3I.png\" width=300px;></img>\n","</p>\n","\n","2. Feature Matching Loss:\n","\n","This loss involves extracting the outputs of every layer from the discriminator for both\n","the generator and ground truth and compare each layer output _k_ using Mean Absolute Error.\n","\n","<p align=\"center\">\n","<img src=\"https://i.imgur.com/gEpSBar.png\" width=400px;></img>\n","</p>\n","\n","**Discriminator Loss**\n","\n","The discriminator uses the Mean Absolute Error and compares the real data predictions\n","with ones and generated predictions with zeros.\n","\n","<p align=\"center\">\n","<img src=\"https://i.imgur.com/bbEnJ3t.png\" width=425px;></img>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0DRr5M13epK"},"outputs":[],"source":["# Generator loss\n","\n","\n","def generator_loss(real_pred, fake_pred):\n","    \"\"\"Loss function for the generator.\n","\n","    Args:\n","        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n","        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n","\n","    Returns:\n","        Loss for the generator.\n","    \"\"\"\n","    gen_loss = []\n","    for i in range(len(fake_pred)):\n","        gen_loss.append(mse(tf.ones_like(fake_pred[i][-1]), fake_pred[i][-1]))\n","\n","    return tf.reduce_mean(gen_loss)\n","\n","\n","def feature_matching_loss(real_pred, fake_pred):\n","    \"\"\"Implements the feature matching loss.\n","\n","    Args:\n","        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n","        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n","\n","    Returns:\n","        Feature Matching Loss.\n","    \"\"\"\n","    fm_loss = []\n","    for i in range(len(fake_pred)):\n","        for j in range(len(fake_pred[i]) - 1):\n","            fm_loss.append(mae(real_pred[i][j], fake_pred[i][j]))\n","\n","    return tf.reduce_mean(fm_loss)\n","\n","\n","def discriminator_loss(real_pred, fake_pred):\n","    \"\"\"Implements the discriminator loss.\n","\n","    Args:\n","        real_pred: Tensor, output of the ground truth wave passed through the discriminator.\n","        fake_pred: Tensor, output of the generator prediction passed through the discriminator.\n","\n","    Returns:\n","        Discriminator Loss.\n","    \"\"\"\n","    real_loss, fake_loss = [], []\n","    for i in range(len(real_pred)):\n","        real_loss.append(mse(tf.ones_like(real_pred[i][-1]), real_pred[i][-1]))\n","        fake_loss.append(mse(tf.zeros_like(fake_pred[i][-1]), fake_pred[i][-1]))\n","\n","    # Calculating the final discriminator loss after scaling\n","    disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n","    return disc_loss\n"]},{"cell_type":"markdown","metadata":{"id":"B2y74xfn3epK"},"source":["Defining the MelGAN model for training.\n","This subclass overrides the `train_step()` method to implement the training logic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3gnVcs83epL"},"outputs":[],"source":["\n","class MelGAN(keras.Model):\n","    def __init__(self, generator, discriminator, **kwargs):\n","        \"\"\"MelGAN trainer class\n","\n","        Args:\n","            generator: keras.Model, Generator model\n","            discriminator: keras.Model, Discriminator model\n","        \"\"\"\n","        super().__init__(**kwargs)\n","        self.generator = generator\n","        self.discriminator = discriminator\n","\n","    def compile(\n","        self,\n","        gen_optimizer,\n","        disc_optimizer,\n","        generator_loss,\n","        feature_matching_loss,\n","        discriminator_loss,\n","    ):\n","        \"\"\"MelGAN compile method.\n","\n","        Args:\n","            gen_optimizer: keras.optimizer, optimizer to be used for training\n","            disc_optimizer: keras.optimizer, optimizer to be used for training\n","            generator_loss: callable, loss function for generator\n","            feature_matching_loss: callable, loss function for feature matching\n","            discriminator_loss: callable, loss function for discriminator\n","        \"\"\"\n","        super().compile()\n","\n","        # Optimizers\n","        self.gen_optimizer = gen_optimizer\n","        self.disc_optimizer = disc_optimizer\n","\n","        # Losses\n","        self.generator_loss = generator_loss\n","        self.feature_matching_loss = feature_matching_loss\n","        self.discriminator_loss = discriminator_loss\n","\n","        # Trackers\n","        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n","        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n","\n","    def train_step(self, batch):\n","        x_batch_train, y_batch_train = batch\n","\n","        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","            # Generating the audio wave\n","            gen_audio_wave = generator(x_batch_train, training=True)\n","\n","            # Generating the features using the discriminator\n","            fake_pred = discriminator(y_batch_train)\n","            real_pred = discriminator(gen_audio_wave)\n","            \n","            # Calculating the generator losses\n","            gen_loss = generator_loss(real_pred, fake_pred)\n","            fm_loss = feature_matching_loss(real_pred, fake_pred)\n","\n","            # Calculating final generator loss\n","            gen_fm_loss = gen_loss + 10 * fm_loss\n","\n","            # Calculating the discriminator losses\n","            disc_loss = discriminator_loss(real_pred, fake_pred)\n","\n","        # Calculating and applying the gradients for generator and discriminator\n","        grads_gen = gen_tape.gradient(gen_fm_loss, generator.trainable_weights)\n","        grads_disc = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n","        gen_optimizer.apply_gradients(zip(grads_gen, generator.trainable_weights))\n","        disc_optimizer.apply_gradients(zip(grads_disc, discriminator.trainable_weights))\n","\n","        self.gen_loss_tracker.update_state(gen_fm_loss)\n","        self.disc_loss_tracker.update_state(disc_loss)\n","\n","        return {\n","            \"gen_loss\": self.gen_loss_tracker.result(),\n","            \"disc_loss\": self.disc_loss_tracker.result(),\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"pUMT6qNN3epM"},"source":["# Training\n","\n","The paper suggests that the training with dynamic shapes takes around 400,000 steps (~500\n","epochs). For this example, we will run it only for a single epoch (819 steps).\n","Longer training time (greater than 300 epochs) will almost certainly provide better results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-kd7u-33epM","outputId":"92c0a6e0-d7a4-4594-d352-5b5ae955ca1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n"]}],"source":["gen_optimizer = keras.optimizers.Adam(\n","    LEARNING_RATE_GEN, beta_1=0.5, beta_2=0.9, clipnorm=1\n",")\n","disc_optimizer = keras.optimizers.Adam(\n","    LEARNING_RATE_DISC, beta_1=0.5, beta_2=0.9, clipnorm=1\n",")\n","\n","# Start training\n","generator = create_generator((None, 1))\n","discriminator = create_discriminator((None, 1))\n","\n","mel_gan = MelGAN(generator, discriminator)\n","mel_gan.compile(\n","    gen_optimizer,\n","    disc_optimizer,\n","    generator_loss,\n","    feature_matching_loss,\n","    discriminator_loss,\n",")\n","mel_gan.fit(\n","    training_data.shuffle(200).batch(BATCH_SIZE), epochs=500\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sqCkQ6XmUk7"},"outputs":[],"source":["generator.save(path_top + \"models/voc.h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/audio/ipynb/melgan_spectrogram_inversion.ipynb","timestamp":1677753083745}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}